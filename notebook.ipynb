{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:32.375596Z",
     "start_time": "2024-08-03T00:40:32.371046Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from utilities import set_multiple_columns_datatype\n",
    "from sklearn.svm import SVC\n"
   ],
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:32.521396Z",
     "start_time": "2024-08-03T00:40:32.377113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train = pd.read_csv('data/train.csv')"
   ],
   "id": "e833652027f20398",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:32.684785Z",
     "start_time": "2024-08-03T00:40:32.522705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = {\"Pclass\":'category', 'Embarked':'category', \"Sex\":'category'}\n",
    "train = set_multiple_columns_datatype(train, columns)"
   ],
   "id": "d5f52b5422834f71",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:32.854342Z",
     "start_time": "2024-08-03T00:40:32.686791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Inspect\n",
    "train.info()"
   ],
   "id": "8324964b27da3327",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  891 non-null    int64   \n",
      " 1   Survived     891 non-null    int64   \n",
      " 2   Pclass       891 non-null    category\n",
      " 3   Name         891 non-null    object  \n",
      " 4   Sex          891 non-null    category\n",
      " 5   Age          714 non-null    float64 \n",
      " 6   SibSp        891 non-null    int64   \n",
      " 7   Parch        891 non-null    int64   \n",
      " 8   Ticket       891 non-null    object  \n",
      " 9   Fare         891 non-null    float64 \n",
      " 10  Cabin        204 non-null    object  \n",
      " 11  Embarked     889 non-null    category\n",
      "dtypes: category(3), float64(2), int64(4), object(3)\n",
      "memory usage: 65.8+ KB\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:33.020461Z",
     "start_time": "2024-08-03T00:40:32.855348Z"
    }
   },
   "cell_type": "code",
   "source": "train.describe()",
   "id": "4b8ced8329887fee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000   80.000000    8.000000    6.000000  512.329200"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:33.327422Z",
     "start_time": "2024-08-03T00:40:33.020461Z"
    }
   },
   "cell_type": "code",
   "source": "train_dummies = pd.get_dummies(train.drop(['Cabin', 'Name', 'Ticket'], axis=1))",
   "id": "96825c2800d358b2",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:33.503326Z",
     "start_time": "2024-08-03T00:40:33.328432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train_dummies.drop(['Survived'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "X_train_dummies, X_test_dummies, y_train_dummies, y_test_dummies = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "987fb09211b716ec",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:33.757587Z",
     "start_time": "2024-08-03T00:40:33.504334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "pipelines = {}\n",
    "for name, model in models.items():\n",
    "    pipelines[name] = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])"
   ],
   "id": "b96cebd3a581738",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:35.653302Z",
     "start_time": "2024-08-03T00:40:33.759663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X_train_dummies, y_train_dummies, cv=5, scoring='accuracy')\n",
    "    results[name] = scores\n",
    "    print(f'{name}: {scores.mean():.2f} ± {scores.std():.2f}')\n"
   ],
   "id": "51c2de3f90b1c649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.80 ± 0.03\n",
      "Random Forest: 0.80 ± 0.01\n",
      "Gradient Boosting: 0.82 ± 0.02\n",
      "SVM: 0.82 ± 0.03\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:36.031643Z",
     "start_time": "2024-08-03T00:40:35.654312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train_dummies, y_train_dummies)\n",
    "    y_pred = pipeline.predict(X_test_dummies)\n",
    "    accuracy = accuracy_score(y_test_dummies, y_pred)\n",
    "    precision = precision_score(y_test_dummies, y_pred)\n",
    "    recall = recall_score(y_test_dummies, y_pred)\n",
    "    f1 = f1_score(y_test_dummies, y_pred)\n",
    "    print(f'\\n{name} Performance on Test Set:')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n"
   ],
   "id": "34e82fe1aae49759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance on Test Set:\n",
      "Accuracy: 0.79\n",
      "Precision: 0.77\n",
      "Recall: 0.72\n",
      "F1 Score: 0.74\n",
      "\n",
      "Random Forest Performance on Test Set:\n",
      "Accuracy: 0.84\n",
      "Precision: 0.84\n",
      "Recall: 0.76\n",
      "F1 Score: 0.79\n",
      "\n",
      "Gradient Boosting Performance on Test Set:\n",
      "Accuracy: 0.82\n",
      "Precision: 0.82\n",
      "Recall: 0.72\n",
      "F1 Score: 0.76\n",
      "\n",
      "SVM Performance on Test Set:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.84\n",
      "Recall: 0.66\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:36.036406Z",
     "start_time": "2024-08-03T00:40:36.032724Z"
    }
   },
   "cell_type": "code",
   "source": "print(X.columns)\n",
   "id": "4518e254564caa82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2',\n",
      "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
      "       'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:40:49.506162Z",
     "start_time": "2024-08-03T00:40:49.179022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model import TitanicModelPipeline\n",
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_pipeline = TitanicModelPipeline()\n",
    "# Train new model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "evaluation_results = model_pipeline.evaluate(X_test, y_test)\n",
    "best_params = model_pipeline.best_params()\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'\\nEvaluation Results on Test Set:')\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f'{metric.capitalize()}: {value:.2f}')"
   ],
   "id": "fdc3ce886e687b25",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    raise\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    if self._final_estimator != \"passthrough\":\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X,\n       \n  File \"C:\\Python312\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    be multiplied by ``weight``.\n                  ^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    \"The transformer outputs a scipy sparse matrix. \"\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    \"The transformer outputs a scipy sparse matrix. \"\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ari Castillo\\Documents\\Programas\\projectos\\Titanic\\model.py\", line 20, in transform\n    def fit(self, X, y):\n                         \n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py\", line 76, in new_method\n    return method(self, other)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py\", line 202, in __mul__\n    return self._arith_method(other, operator.mul)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py\", line 6126, in _arith_method\n    return base.IndexOpsMixin._arith_method(self, other, op)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\base.py\", line 1382, in _arith_method\n    result = ops.arithmetic_op(lvalues, rvalues, op)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 273, in arithmetic_op\n    res_values = op(left, right)\n                 ^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py\", line 1692, in __array_ufunc__\n    raise TypeError(\nTypeError: Object with dtype category cannot perform the numpy op multiply\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[184], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m model_pipeline \u001B[38;5;241m=\u001B[39m TitanicModelPipeline()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Train new model\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mmodel_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Evaluation\u001B[39;00m\n\u001B[0;32m     11\u001B[0m evaluation_results \u001B[38;5;241m=\u001B[39m model_pipeline\u001B[38;5;241m.\u001B[39mevaluate(X_test, y_test)\n",
      "File \u001B[1;32m~\\Documents\\Programas\\projectos\\Titanic\\model.py:42\u001B[0m, in \u001B[0;36mTitanicModelPipeline.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     36\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_selection__k\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m],\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier__n_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m200\u001B[39m],\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier__max_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m20\u001B[39m]\n\u001B[0;32m     40\u001B[0m }\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipeline, param_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 42\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mfit\u001B[1;34m(self, X, y, **params)\u001B[0m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001B[0m, in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    raise\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    if self._final_estimator != \"passthrough\":\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X,\n       \n  File \"C:\\Python312\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    be multiplied by ``weight``.\n                  ^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    \"The transformer outputs a scipy sparse matrix. \"\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    \"The transformer outputs a scipy sparse matrix. \"\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ari Castillo\\Documents\\Programas\\projectos\\Titanic\\model.py\", line 20, in transform\n    def fit(self, X, y):\n                         \n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py\", line 76, in new_method\n    return method(self, other)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py\", line 202, in __mul__\n    return self._arith_method(other, operator.mul)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py\", line 6126, in _arith_method\n    return base.IndexOpsMixin._arith_method(self, other, op)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\base.py\", line 1382, in _arith_method\n    result = ops.arithmetic_op(lvalues, rvalues, op)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 273, in arithmetic_op\n    res_values = op(left, right)\n                 ^^^^^^^^^^^^^^^\n  File \"C:\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py\", line 1692, in __array_ufunc__\n    raise TypeError(\nTypeError: Object with dtype category cannot perform the numpy op multiply\n"
     ]
    }
   ],
   "execution_count": 184
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
